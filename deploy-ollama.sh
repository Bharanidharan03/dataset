#!/bin/bash

# Deployment Script for Ollama on a Cloud GPU Server (Ubuntu/Debian)
# Run this on your remote server to prepare it for your Medical Analyzer app.

echo "ğŸš€ Starting Ollama Cloud Deployment..."

# 1. Update and Install Dependencies
sudo apt-get update
sudo apt-get install -y curl ca-certificates nmap

# 2. Install Ollama
echo "ğŸ“¦ Installing Ollama..."
curl -fsSL https://ollama.com/install.sh | sh

# 3. Configure Ollama for External Access
echo "âš™ï¸ Configuring Ollama environment variables..."
# We need to set OLLAMA_HOST to 0.0.0.0 and OLLAMA_ORIGINS to * for cross-origin requests
sudo mkdir -p /etc/systemd/system/ollama.service.d
cat <<EOF | sudo tee /etc/systemd/system/ollama.service.d/override.conf
[Service]
Environment="OLLAMA_HOST=0.0.0.0"
Environment="OLLAMA_ORIGINS=*"
EOF

# 4. Reload Systemd and Restart Ollama
echo "ğŸ”„ Restarting Ollama service..."
sudo systemctl daemon-reload
sudo systemctl restart ollama

# 5. Pre-pull the recommended model
echo "ğŸ“¥ Pre-pulling Llama3 model (this may take a few minutes)..."
ollama pull llama3

echo "âœ… Ollama is now running on port 11434!"
echo "ğŸ“ Your Server IP: $(curl -s ifconfig.me)"
echo "âš ï¸ IMPORTANT: Ensure port 11434 is OPEN in your cloud provider's firewall (AWS/GCP/Azure)."
